# -*- coding: utf-8 -*-
"""image_classification_pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MrB77q1Tvz9caUxIXjaBzM-ZZAIxitm0
"""

!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
!unzip -q tiny-imagenet-200.zip

import torchvision
from torchvision import transforms

train_data_path = 'tiny-imagenet-200/train'
val_data_path = 'tiny-imagenet-200/val'
test_data_path = 'tiny-imagenet-200/test'

transforms = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
    std=[0.229, 0.224, 0.225] )
])

train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=transforms)
val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform=transforms)
test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=transforms)

import torch

batch_size = 64
train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)
val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)
test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)

# Assuming train_set is the Dataset object, such as datasets.CIFAR10 or datasets.ImageFolder
print("Number of samples:", len(train_data))  # Total number of samples

# Access a single sample
sample, label = train_data[0]
print("Sample shape:", sample.shape if isinstance(sample, torch.Tensor) else "Varies by dataset")
print("Label:", label)

# If the dataset has classes (e.g., ImageFolder or CIFAR10), you can access them like this:
if hasattr(train_data, 'classes'):
    print("Classes:", train_data.classes)  # List of class names
    print("Number of classes:", len(train_data.classes))

from torch import nn
import torch.nn.functional as F

class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(1288, 84)
        self.fc2 = nn.Linear(84, 50)
        self.fc3 = nn.Linear(50, 2)

    def forward(self, x):
        x = x.view(-1, 1288)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.softmax(self.fc3(x), dim=1)
        return x

simplenet = SimpleNet()

import torch.optim as optim

optimizer = optim.Adam(simplenet.parameters(), lr=0.001)

import torch
import torch.nn.functional as F

def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device="cpu"):
    for epoch in range(epochs):
        training_loss = 0.0
        valid_loss = 0.0
        model.train()

        # Training Loop
        for batch in train_loader:
            optimizer.zero_grad()
            inputs, targets = batch
            inputs, targets = inputs.to(device), targets.to(device)  # Move both inputs and targets to device

            # Forward pass
            output = model(inputs)
            loss = loss_fn(output, targets)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            training_loss += loss.item()

        # Calculate average training loss
        training_loss /= len(train_loader)

        # Validation Loop
        model.eval()
        num_correct = 0
        num_examples = 0
        with torch.no_grad():  # Disable gradient calculations for validation
            for batch in val_loader:
                inputs, targets = batch
                inputs, targets = inputs.to(device), targets.to(device)

                # Forward pass
                output = model(inputs)
                loss = loss_fn(output, targets)
                valid_loss += loss.item()

                # Calculate accuracy
                predictions = torch.argmax(F.softmax(output, dim=1), dim=1)
                correct = predictions.eq(targets)
                num_correct += correct.sum().item()
                num_examples += correct.shape[0]

        # Calculate average validation loss
        valid_loss /= len(val_loader)

        # Print statistics
        accuracy = num_correct / num_examples
        print(f'Epoch: {epoch + 1}, Training Loss: {training_loss:.2f}, Validation Loss: {valid_loss:.2f}, Accuracy: {accuracy:.2f}')

device = "cpu"
epochs = 20

train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, val_data_loader, epochs, device)

torch.save(simplenet, "/tmp/simplenet")

### loading the model
simplenet = torch.load("/tmp/simplenet")

## saving the state dict
torch.save(simplenet.state_dict(), "/content/simplenet")

simplenet = SimpleNet()
simple_state_dict = torch.load("/content/simplenet")
simplenet.load_state_dict(simple_state_dict)

